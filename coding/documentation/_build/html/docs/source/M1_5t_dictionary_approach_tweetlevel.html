
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>M1_5t_dictionary_approach_tweetlevel module &#8212; Hate Speech Detection with Deep Learning Models in PyTorch April 2020 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-M1_5t_dictionary_approach_tweetlevel">
<span id="m1-5t-dictionary-approach-tweetlevel-module"></span><h1>M1_5t_dictionary_approach_tweetlevel module<a class="headerlink" href="#module-M1_5t_dictionary_approach_tweetlevel" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="M1_5t_dictionary_approach_tweetlevel.hatesearch">
<code class="sig-prename descclassname">M1_5t_dictionary_approach_tweetlevel.</code><code class="sig-name descname">hatesearch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dictionary</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">average_hate</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">difflib_percentage</span><span class="o">=</span><span class="default_value">0.85</span></em><span class="sig-paren">)</span><a class="headerlink" href="#M1_5t_dictionary_approach_tweetlevel.hatesearch" title="Permalink to this definition">¶</a></dt>
<dd><p>This function matches the terms in the Hatebase.org dictionary with the tweets in our dataset. Each word in the tweet gets assigned a number based on its hatefulness, based on hatebase.org (hatefulness is determined by the word appearing in the dictionary, its ambiguity as a term of hatespeech, its average offensiveness (as defined by hatebase.org methodology). The output is a tensor used for further analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>str</em>) – The input, a string (in this a tweet) from our dataframe</p></li>
<li><p><strong>dictionary</strong> (<em>dataframe</em>) – a dataframe containing hateful terms, default is an up-to-date extraction of English-language terms from Hatebase.org</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Whether or not outputs from print-Functions (used for testing purposes) should be shown</p></li>
<li><p><strong>average_hate</strong> (<em>bool</em>) – Determines if a word in a tweet is found in multiple hate-dictionary entries, what value of hatefulness should be used. If “False”, the maximum is used. If “True” (Default), the average is calculated.</p></li>
<li><p><strong>difflib_percentage</strong> (<em>float</em>) – Percentage used to determine how sensible the matching function of words in the tweets with terms in the dictionary should be (in order to catch words with typos or small changes, which have been deliberately included in order to avoid detection, idea adapted from Chiu (2018): <a class="reference external" href="https://ethanchiu.xyz/blog/2018/02/03/Identifying-Hate/">https://ethanchiu.xyz/blog/2018/02/03/Identifying-Hate/</a>). Default: 0.85.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of numbers for each word in the tweet, indicating hatefulness of the word</p>
</dd>
</dl>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Hate Speech Detection with Deep Learning Models in PyTorch</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Carlos Eduardo Posada, Maximilian Kupi, Michael Bodnar, and Nikolas Schmidt.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/docs/source/M1_5t_dictionary_approach_tweetlevel.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>