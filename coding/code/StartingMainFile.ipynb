{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StartingMainFile.ipynb","provenance":[],"mount_file_id":"1_cqbtzIA1bd2tpIQfdgpzmx--PcCPOlm","authorship_tag":"ABX9TyNhEI84v7jfLaQ9/A6snCAo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2lFidrGRCDmg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"ae9d281c-0fc1-4022-f32e-d1cfcde114b0","executionInfo":{"status":"ok","timestamp":1585850339299,"user_tz":-120,"elapsed":4928,"user":{"displayName":"Maximilian Kupi","photoUrl":"","userId":"17277613217804122571"}}},"source":["# installing required packages \n","!pip install torchviz"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting torchviz\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 33.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 36.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 9.5MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.4.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3523 sha256=168f1d454f811fa20f3569f7d9a2283a01cd69f577305957cfed27bac15b667a\n","  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jyGblewezUgK","colab_type":"code","outputId":"ad7bfe6f-7a3a-4e73-f751-594fb3763637","executionInfo":{"status":"ok","timestamp":1585850233500,"user_tz":-120,"elapsed":4342,"user":{"displayName":"Maximilian Kupi","photoUrl":"","userId":"17277613217804122571"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Setting relative path to Working directory\n","import os\n","os.chdir(\"/content/drive/My Drive/Masterstudium/Inhalte/4th Semester/NLP/nlp-project/coding/code\")\n","!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Masterstudium/Inhalte/4th Semester/NLP/nlp-project/coding/code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ohf9p9wrzvl9","colab_type":"code","outputId":"72b34af3-89b5-4acb-ee93-d67364612df8","executionInfo":{"status":"ok","timestamp":1585853019029,"user_tz":-120,"elapsed":1535960,"user":{"displayName":"Maximilian Kupi","photoUrl":"","userId":"17277613217804122571"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python \"MAIN.py\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["{'global': {'path': 'exchange_base/'}, 'CNN': {'layers': {'1': {'Conv1d': {'in_channels': 120, 'out_channels': 16, 'kernel_size': 3}, 'BatchNorm1d': {'num_features': 16}, 'MaxPool2d': {'kernel_size': 2, 'stride': 2}}, '2': {'Conv1d': {'in_channels': 16, 'out_channels': 32, 'kernel_size': 3}, 'BatchNorm1d': {'num_features': 32}, 'MaxPool2d': {'kernel_size': 2, 'stride': 2}}}, 'fc.Linear': {'in_features': 32, 'out_features': 3}}, 'optimizer': {'learning_rate': 0.001}, 'training': {'epochs': 50, 'input': {'batch_size': 16, 'vectors': 'exchange_base/train_vectorized.pt', 'labels': 'exchange_base/train_labels.pt'}}, 'output': {'filepath': 'exchange_base/first_long_trainingtrain_model_epochs50.ckpt'}, 'validation': {'input': {'model': 'exchange_base/first_long_trainingtrain_model_epochs50.ckpt', 'result': 'exchange_base/first_long_trainingval_result.json', 'batch_size': 1, 'vectors': 'exchange_base/val_vectorized.pt', 'labels': 'exchange_base/val_labels.pt'}}}\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla P4\n","Demo Vector entry\n","tensor([  101.,  2017.,  2228.,  1996.,  2293.,  6771.,  2005.,  7055.,  2097.,\n","         2058., 15637.,  2008.,  2002.,  1005.,  1055.,  3920.,  1998.,  2062.,\n","         3144.,  2054.,  2515.,  2008.,  2812.,   102.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.])\n","Demo Label entry\n","tensor(2)\n","Demo Vector entry\n","tensor([  101.,  6203.,  2057.,  2004.,  2028.,  8438.,  2024.,  4851.,  2017.,\n","         2000.,  2644.,  5983.,  2041., 28662.,  8884.,  2814.,  6077.,  1998.,\n","         8870.,  2023.,  2003.,  6135.,  9576.,   102.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n","            0.,     0.,     0.])\n","Demo Label entry\n","tensor(0)\n","Sequential(\n","  (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,))\n","  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU()\n",")\n","Sequential(\n","  (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n","  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU()\n",")\n","Sequential(\n","  (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n","  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU()\n",")\n","Linear(in_features=7296, out_features=3, bias=True)\n","Epoch [1/50], Step [1000/4846], Loss: 1.0854\n","Epoch [1/50], Step [2000/4846], Loss: 0.9142\n","Epoch [1/50], Step [3000/4846], Loss: 0.9885\n","Epoch [1/50], Step [4000/4846], Loss: 1.0115\n","Test Accuracy on Validation: 57.4941620153305 %\n","F1-score Macro on Validation: 0.4817316394101332\n","Precision of Hate on Validation: 0.125195007800312\n","Recall of Hate on Validation: 0.33229813664596275\n","F1-score of Hate on Validation: 0.18186968838526912\n","Epoch [2/50], Step [1000/4846], Loss: 0.9011\n","Epoch [2/50], Step [2000/4846], Loss: 0.8219\n","Epoch [2/50], Step [3000/4846], Loss: 0.8919\n","Epoch [2/50], Step [4000/4846], Loss: 0.9584\n","Test Accuracy on Validation: 59.41446973549942 %\n","F1-score Macro on Validation: 0.4902720191158226\n","Precision of Hate on Validation: 0.13075849232201023\n","Recall of Hate on Validation: 0.2908902691511387\n","F1-score of Hate on Validation: 0.18041733547351527\n","Epoch [3/50], Step [1000/4846], Loss: 0.9056\n","Epoch [3/50], Step [2000/4846], Loss: 0.9792\n","Epoch [3/50], Step [3000/4846], Loss: 1.0782\n","Epoch [3/50], Step [4000/4846], Loss: 0.7908\n","Test Accuracy on Validation: 59.45392422267436 %\n","F1-score Macro on Validation: 0.4965045030300712\n","Precision of Hate on Validation: 0.12415026833631485\n","Recall of Hate on Validation: 0.35921325051759834\n","F1-score of Hate on Validation: 0.18452539218293007\n","Epoch [4/50], Step [1000/4846], Loss: 1.1726\n","Epoch [4/50], Step [2000/4846], Loss: 0.9982\n","Epoch [4/50], Step [3000/4846], Loss: 0.9838\n","Epoch [4/50], Step [4000/4846], Loss: 0.7411\n","Test Accuracy on Validation: 59.02259308915807 %\n","F1-score Macro on Validation: 0.494899894208687\n","Precision of Hate on Validation: 0.12191209496310555\n","Recall of Hate on Validation: 0.39337474120082816\n","F1-score of Hate on Validation: 0.1861376438892971\n","Epoch [5/50], Step [1000/4846], Loss: 1.0744\n","Epoch [5/50], Step [2000/4846], Loss: 1.0025\n","Epoch [5/50], Step [3000/4846], Loss: 0.6584\n","Epoch [5/50], Step [4000/4846], Loss: 0.7548\n","Test Accuracy on Validation: 59.549880046706726 %\n","F1-score Macro on Validation: 0.49620326444001117\n","Precision of Hate on Validation: 0.1230889847118777\n","Recall of Hate on Validation: 0.3250517598343685\n","F1-score of Hate on Validation: 0.17856127381290873\n","Epoch [6/50], Step [1000/4846], Loss: 1.1413\n","Epoch [6/50], Step [2000/4846], Loss: 0.9061\n","Epoch [6/50], Step [3000/4846], Loss: 0.6612\n","Epoch [6/50], Step [4000/4846], Loss: 0.7171\n","Test Accuracy on Validation: 55.64395476113042 %\n","F1-score Macro on Validation: 0.4737771801108317\n","Precision of Hate on Validation: 0.10429011614126571\n","Recall of Hate on Validation: 0.4554865424430642\n","F1-score of Hate on Validation: 0.16972034715525558\n","Epoch [7/50], Step [1000/4846], Loss: 1.0291\n","Epoch [7/50], Step [2000/4846], Loss: 0.8409\n","Epoch [7/50], Step [3000/4846], Loss: 0.7851\n","Epoch [7/50], Step [4000/4846], Loss: 0.8958\n","Test Accuracy on Validation: 60.00157460342213 %\n","F1-score Macro on Validation: 0.4971118727361043\n","Precision of Hate on Validation: 0.1193929173693086\n","Recall of Hate on Validation: 0.36645962732919257\n","F1-score of Hate on Validation: 0.18010684304248284\n","Epoch [8/50], Step [1000/4846], Loss: 1.1382\n","Epoch [8/50], Step [2000/4846], Loss: 0.6014\n","Epoch [8/50], Step [3000/4846], Loss: 0.9127\n","Epoch [8/50], Step [4000/4846], Loss: 0.8717\n","Test Accuracy on Validation: 60.691026921817844 %\n","F1-score Macro on Validation: 0.4998020295827998\n","Precision of Hate on Validation: 0.12530626531326566\n","Recall of Hate on Validation: 0.37060041407867494\n","F1-score of Hate on Validation: 0.18728747057284856\n","Epoch [9/50], Step [1000/4846], Loss: 0.7069\n","Epoch [9/50], Step [2000/4846], Loss: 0.8077\n","Epoch [9/50], Step [3000/4846], Loss: 0.9483\n","Epoch [9/50], Step [4000/4846], Loss: 1.3586\n","Test Accuracy on Validation: 57.89987546231949 %\n","F1-score Macro on Validation: 0.4874209370763281\n","Precision of Hate on Validation: 0.11970474967907574\n","Recall of Hate on Validation: 0.386128364389234\n","F1-score of Hate on Validation: 0.1827535521803038\n","Epoch [10/50], Step [1000/4846], Loss: 0.7533\n","Epoch [10/50], Step [2000/4846], Loss: 0.8039\n","Epoch [10/50], Step [3000/4846], Loss: 0.6934\n","Epoch [10/50], Step [4000/4846], Loss: 0.7563\n","Test Accuracy on Validation: 58.51164085820983 %\n","F1-score Macro on Validation: 0.4845384734648617\n","Precision of Hate on Validation: 0.10683229813664596\n","Recall of Hate on Validation: 0.35610766045548653\n","F1-score of Hate on Validation: 0.1643573817486861\n","Epoch [11/50], Step [1000/4846], Loss: 0.4496\n","Epoch [11/50], Step [2000/4846], Loss: 0.7653\n","Epoch [11/50], Step [3000/4846], Loss: 0.8674\n","Epoch [11/50], Step [4000/4846], Loss: 0.6962\n","Test Accuracy on Validation: 60.4472251476457 %\n","F1-score Macro on Validation: 0.4999080152657685\n","Precision of Hate on Validation: 0.12048990400529626\n","Recall of Hate on Validation: 0.37681159420289856\n","F1-score of Hate on Validation: 0.18259342864309003\n","Epoch [12/50], Step [1000/4846], Loss: 0.6862\n","Epoch [12/50], Step [2000/4846], Loss: 0.8733\n","Epoch [12/50], Step [3000/4846], Loss: 0.8764\n","Epoch [12/50], Step [4000/4846], Loss: 0.8236\n","Test Accuracy on Validation: 61.70703315199259 %\n","F1-score Macro on Validation: 0.5012928403842013\n","Precision of Hate on Validation: 0.12047743379336069\n","Recall of Hate on Validation: 0.33436853002070394\n","F1-score of Hate on Validation: 0.17713188922401976\n","Epoch [13/50], Step [1000/4846], Loss: 0.4628\n","Epoch [13/50], Step [2000/4846], Loss: 0.7102\n","Epoch [13/50], Step [3000/4846], Loss: 1.1545\n","Epoch [13/50], Step [4000/4846], Loss: 0.7868\n","Test Accuracy on Validation: 61.38409571321186 %\n","F1-score Macro on Validation: 0.5008340115448298\n","Precision of Hate on Validation: 0.12916063675832126\n","Recall of Hate on Validation: 0.3695652173913043\n","F1-score of Hate on Validation: 0.19142091152815013\n","Epoch [14/50], Step [1000/4846], Loss: 0.4366\n","Epoch [14/50], Step [2000/4846], Loss: 0.7232\n","Epoch [14/50], Step [3000/4846], Loss: 0.7398\n","Epoch [14/50], Step [4000/4846], Loss: 0.6608\n","Test Accuracy on Validation: 59.9516892622828 %\n","F1-score Macro on Validation: 0.49948936605048483\n","Precision of Hate on Validation: 0.12637913741223672\n","Recall of Hate on Validation: 0.391304347826087\n","F1-score of Hate on Validation: 0.19105382865807433\n","Epoch [15/50], Step [1000/4846], Loss: 0.9454\n","Epoch [15/50], Step [2000/4846], Loss: 0.6292\n","Epoch [15/50], Step [3000/4846], Loss: 1.0947\n","Epoch [15/50], Step [4000/4846], Loss: 0.5295\n","Test Accuracy on Validation: 59.5358287825432 %\n","F1-score Macro on Validation: 0.49306534525827256\n","Precision of Hate on Validation: 0.11691153485464208\n","Recall of Hate on Validation: 0.38716356107660455\n","F1-score of Hate on Validation: 0.17959183673469387\n","Epoch [16/50], Step [1000/4846], Loss: 0.8938\n","Epoch [16/50], Step [2000/4846], Loss: 0.6634\n","Epoch [16/50], Step [3000/4846], Loss: 0.6341\n","Epoch [16/50], Step [4000/4846], Loss: 0.6629\n","Test Accuracy on Validation: 61.74137573986971 %\n","F1-score Macro on Validation: 0.5039043167264808\n","Precision of Hate on Validation: 0.12870114488748519\n","Recall of Hate on Validation: 0.33747412008281574\n","F1-score of Hate on Validation: 0.18633895398685338\n","Epoch [17/50], Step [1000/4846], Loss: 0.7645\n","Epoch [17/50], Step [2000/4846], Loss: 0.7736\n","Epoch [17/50], Step [3000/4846], Loss: 0.9412\n","Epoch [17/50], Step [4000/4846], Loss: 1.2105\n","Test Accuracy on Validation: 58.30031138488029 %\n","F1-score Macro on Validation: 0.4849871390183294\n","Precision of Hate on Validation: 0.11568627450980393\n","Recall of Hate on Validation: 0.36645962732919257\n","F1-score of Hate on Validation: 0.17585692995529062\n","Epoch [18/50], Step [1000/4846], Loss: 0.6103\n","Epoch [18/50], Step [2000/4846], Loss: 0.5947\n","Epoch [18/50], Step [3000/4846], Loss: 0.8043\n","Epoch [18/50], Step [4000/4846], Loss: 0.7210\n","Test Accuracy on Validation: 58.84578135437816 %\n","F1-score Macro on Validation: 0.4906134956535917\n","Precision of Hate on Validation: 0.11550632911392406\n","Recall of Hate on Validation: 0.3778467908902691\n","F1-score of Hate on Validation: 0.1769268056228793\n","Epoch [19/50], Step [1000/4846], Loss: 0.4728\n","Epoch [19/50], Step [2000/4846], Loss: 0.6032\n","Epoch [19/50], Step [3000/4846], Loss: 0.8049\n","Epoch [19/50], Step [4000/4846], Loss: 0.9132\n","Test Accuracy on Validation: 59.04442888159326 %\n","F1-score Macro on Validation: 0.4914825566948901\n","Precision of Hate on Validation: 0.12078651685393259\n","Recall of Hate on Validation: 0.40062111801242234\n","F1-score of Hate on Validation: 0.18561151079136692\n","Epoch [20/50], Step [1000/4846], Loss: 0.6697\n","Epoch [20/50], Step [2000/4846], Loss: 0.6192\n","Epoch [20/50], Step [3000/4846], Loss: 0.7018\n","Epoch [20/50], Step [4000/4846], Loss: 0.8224\n","Test Accuracy on Validation: 58.911003887476284 %\n","F1-score Macro on Validation: 0.49076143826496726\n","Precision of Hate on Validation: 0.1205901218729955\n","Recall of Hate on Validation: 0.38923395445134573\n","F1-score of Hate on Validation: 0.1841332027424094\n","Epoch [21/50], Step [1000/4846], Loss: 0.4328\n","Epoch [21/50], Step [2000/4846], Loss: 0.5023\n","Epoch [21/50], Step [3000/4846], Loss: 0.5969\n","Epoch [21/50], Step [4000/4846], Loss: 0.4779\n","Test Accuracy on Validation: 59.689235087510184 %\n","F1-score Macro on Validation: 0.49549404425867277\n","Precision of Hate on Validation: 0.12904398400581607\n","Recall of Hate on Validation: 0.36749482401656314\n","F1-score of Hate on Validation: 0.19101425881086898\n","Epoch [22/50], Step [1000/4846], Loss: 0.8435\n","Epoch [22/50], Step [2000/4846], Loss: 0.4328\n","Epoch [22/50], Step [3000/4846], Loss: 0.6669\n","Epoch [22/50], Step [4000/4846], Loss: 0.8237\n","Test Accuracy on Validation: 60.58789525136606 %\n","F1-score Macro on Validation: 0.5030976733006645\n","Precision of Hate on Validation: 0.131189948263119\n","Recall of Hate on Validation: 0.36749482401656314\n","F1-score of Hate on Validation: 0.19335511982570808\n","Epoch [23/50], Step [1000/4846], Loss: 0.4276\n","Epoch [23/50], Step [2000/4846], Loss: 0.5342\n","Epoch [23/50], Step [3000/4846], Loss: 0.9829\n","Epoch [23/50], Step [4000/4846], Loss: 0.8593\n","Test Accuracy on Validation: 60.984791215060056 %\n","F1-score Macro on Validation: 0.5083094741004799\n","Precision of Hate on Validation: 0.1304034582132565\n","Recall of Hate on Validation: 0.3747412008281574\n","F1-score of Hate on Validation: 0.19347942276857297\n","Epoch [24/50], Step [1000/4846], Loss: 0.6708\n","Epoch [24/50], Step [2000/4846], Loss: 0.6109\n","Epoch [24/50], Step [3000/4846], Loss: 0.4313\n","Epoch [24/50], Step [4000/4846], Loss: 0.8189\n","Test Accuracy on Validation: 60.868088131696815 %\n","F1-score Macro on Validation: 0.5048290603570073\n","Precision of Hate on Validation: 0.13069586718474038\n","Recall of Hate on Validation: 0.3830227743271222\n","F1-score of Hate on Validation: 0.19489070318672638\n","Epoch [25/50], Step [1000/4846], Loss: 0.5995\n","Epoch [25/50], Step [2000/4846], Loss: 0.9498\n","Epoch [25/50], Step [3000/4846], Loss: 0.5163\n","Epoch [25/50], Step [4000/4846], Loss: 0.7595\n","Test Accuracy on Validation: 59.65446465660855 %\n","F1-score Macro on Validation: 0.49579397383879303\n","Precision of Hate on Validation: 0.11742892459826947\n","Recall of Hate on Validation: 0.39337474120082816\n","F1-score of Hate on Validation: 0.1808662541646835\n","Epoch [26/50], Step [1000/4846], Loss: 0.9424\n","Epoch [26/50], Step [2000/4846], Loss: 0.5679\n","Epoch [26/50], Step [3000/4846], Loss: 0.4196\n","Epoch [26/50], Step [4000/4846], Loss: 0.4524\n","Test Accuracy on Validation: 60.327135952709675 %\n","F1-score Macro on Validation: 0.4965421002807094\n","Precision of Hate on Validation: 0.12253903598099117\n","Recall of Hate on Validation: 0.37370600414078675\n","F1-score of Hate on Validation: 0.184560327198364\n","Epoch [27/50], Step [1000/4846], Loss: 0.8423\n","Epoch [27/50], Step [2000/4846], Loss: 0.4681\n","Epoch [27/50], Step [3000/4846], Loss: 0.4648\n","Epoch [27/50], Step [4000/4846], Loss: 0.7121\n","Test Accuracy on Validation: 60.19277904674423 %\n","F1-score Macro on Validation: 0.4995519090453646\n","Precision of Hate on Validation: 0.12566940378436273\n","Recall of Hate on Validation: 0.36438923395445133\n","F1-score of Hate on Validation: 0.1868861162728962\n","Epoch [28/50], Step [1000/4846], Loss: 0.9448\n","Epoch [28/50], Step [2000/4846], Loss: 0.6209\n","Epoch [28/50], Step [3000/4846], Loss: 0.5145\n","Epoch [28/50], Step [4000/4846], Loss: 0.6030\n","Test Accuracy on Validation: 61.06630975639033 %\n","F1-score Macro on Validation: 0.5050987792064477\n","Precision of Hate on Validation: 0.12916063675832126\n","Recall of Hate on Validation: 0.3695652173913043\n","F1-score of Hate on Validation: 0.19142091152815013\n","Epoch [29/50], Step [1000/4846], Loss: 0.6622\n","Epoch [29/50], Step [2000/4846], Loss: 0.9859\n","Epoch [29/50], Step [3000/4846], Loss: 0.7945\n","Epoch [29/50], Step [4000/4846], Loss: 0.4599\n","Test Accuracy on Validation: 60.69338241887552 %\n","F1-score Macro on Validation: 0.5069964900076805\n","Precision of Hate on Validation: 0.13480303577882183\n","Recall of Hate on Validation: 0.386128364389234\n","F1-score of Hate on Validation: 0.1998392713635146\n","Epoch [30/50], Step [1000/4846], Loss: 1.5479\n","Epoch [30/50], Step [2000/4846], Loss: 0.7732\n","Epoch [30/50], Step [3000/4846], Loss: 0.5485\n","Epoch [30/50], Step [4000/4846], Loss: 0.8605\n","Test Accuracy on Validation: 62.749459041039735 %\n","F1-score Macro on Validation: 0.5125946035558475\n","Precision of Hate on Validation: 0.13748378728923477\n","Recall of Hate on Validation: 0.32919254658385094\n","F1-score of Hate on Validation: 0.1939615736505032\n","Epoch [31/50], Step [1000/4846], Loss: 0.7812\n","Epoch [31/50], Step [2000/4846], Loss: 0.7021\n","Epoch [31/50], Step [3000/4846], Loss: 0.5678\n","Epoch [31/50], Step [4000/4846], Loss: 0.5410\n","Test Accuracy on Validation: 61.97435717649535 %\n","F1-score Macro on Validation: 0.5104897031288982\n","Precision of Hate on Validation: 0.13588442014837954\n","Recall of Hate on Validation: 0.36024844720496896\n","F1-score of Hate on Validation: 0.1973348454777431\n","Epoch [32/50], Step [1000/4846], Loss: 0.6350\n","Epoch [32/50], Step [2000/4846], Loss: 0.5202\n","Epoch [32/50], Step [3000/4846], Loss: 0.7823\n","Epoch [32/50], Step [4000/4846], Loss: 0.8624\n","Test Accuracy on Validation: 62.201410936014234 %\n","F1-score Macro on Validation: 0.5097241930044585\n","Precision of Hate on Validation: 0.13296749683410722\n","Recall of Hate on Validation: 0.32608695652173914\n","F1-score of Hate on Validation: 0.1889055472263868\n","Epoch [33/50], Step [1000/4846], Loss: 0.6004\n","Epoch [33/50], Step [2000/4846], Loss: 0.4306\n","Epoch [33/50], Step [3000/4846], Loss: 0.7188\n","Epoch [33/50], Step [4000/4846], Loss: 0.5075\n","Test Accuracy on Validation: 60.19848987396996 %\n","F1-score Macro on Validation: 0.49745749423756863\n","Precision of Hate on Validation: 0.11911357340720222\n","Recall of Hate on Validation: 0.35610766045548653\n","F1-score of Hate on Validation: 0.1785158277114686\n","Epoch [34/50], Step [1000/4846], Loss: 0.5628\n","Epoch [34/50], Step [2000/4846], Loss: 0.8811\n","Epoch [34/50], Step [3000/4846], Loss: 0.6031\n","Epoch [34/50], Step [4000/4846], Loss: 0.5818\n","Test Accuracy on Validation: 60.27395413300847 %\n","F1-score Macro on Validation: 0.4963366215183311\n","Precision of Hate on Validation: 0.11442112389979689\n","Recall of Hate on Validation: 0.3498964803312629\n","F1-score of Hate on Validation: 0.17244897959183672\n","Epoch [35/50], Step [1000/4846], Loss: 0.4948\n","Epoch [35/50], Step [2000/4846], Loss: 0.5515\n","Epoch [35/50], Step [3000/4846], Loss: 0.4428\n","Epoch [35/50], Step [4000/4846], Loss: 0.8427\n","Test Accuracy on Validation: 61.51606476063035 %\n","F1-score Macro on Validation: 0.5061905841416827\n","Precision of Hate on Validation: 0.13286713286713286\n","Recall of Hate on Validation: 0.35403726708074534\n","F1-score of Hate on Validation: 0.19322033898305083\n","Epoch [36/50], Step [1000/4846], Loss: 1.0071\n","Epoch [36/50], Step [2000/4846], Loss: 0.6976\n","Epoch [36/50], Step [3000/4846], Loss: 0.5884\n","Epoch [36/50], Step [4000/4846], Loss: 0.6875\n","Test Accuracy on Validation: 61.3894339032824 %\n","F1-score Macro on Validation: 0.5072210887756309\n","Precision of Hate on Validation: 0.1260593220338983\n","Recall of Hate on Validation: 0.3695652173913043\n","F1-score of Hate on Validation: 0.18799368088467616\n","Epoch [37/50], Step [1000/4846], Loss: 0.8017\n","Epoch [37/50], Step [2000/4846], Loss: 0.7002\n","Epoch [37/50], Step [3000/4846], Loss: 0.5405\n","Epoch [37/50], Step [4000/4846], Loss: 0.5422\n","Test Accuracy on Validation: 61.6006910314768 %\n","F1-score Macro on Validation: 0.5089612597936561\n","Precision of Hate on Validation: 0.1357921207041073\n","Recall of Hate on Validation: 0.33540372670807456\n","F1-score of Hate on Validation: 0.19331742243436756\n","Epoch [38/50], Step [1000/4846], Loss: 0.6065\n","Epoch [38/50], Step [2000/4846], Loss: 0.4825\n","Epoch [38/50], Step [3000/4846], Loss: 0.6121\n","Epoch [38/50], Step [4000/4846], Loss: 0.8583\n","Test Accuracy on Validation: 62.080545886187224 %\n","F1-score Macro on Validation: 0.510946472967965\n","Precision of Hate on Validation: 0.1306394664574343\n","Recall of Hate on Validation: 0.3447204968944099\n","F1-score of Hate on Validation: 0.18947368421052632\n","Epoch [39/50], Step [1000/4846], Loss: 0.6370\n","Epoch [39/50], Step [2000/4846], Loss: 0.6905\n","Epoch [39/50], Step [3000/4846], Loss: 0.7370\n","Epoch [39/50], Step [4000/4846], Loss: 0.7001\n","Test Accuracy on Validation: 60.934185507041946 %\n","F1-score Macro on Validation: 0.505022504398054\n","Precision of Hate on Validation: 0.12918315940985967\n","Recall of Hate on Validation: 0.37163561076604557\n","F1-score of Hate on Validation: 0.1917222963951936\n","Epoch [40/50], Step [1000/4846], Loss: 0.8037\n","Epoch [40/50], Step [2000/4846], Loss: 0.9469\n","Epoch [40/50], Step [3000/4846], Loss: 0.3623\n","Epoch [40/50], Step [4000/4846], Loss: 0.5391\n","Test Accuracy on Validation: 61.552597144599744 %\n","F1-score Macro on Validation: 0.506386763936262\n","Precision of Hate on Validation: 0.13003324713705208\n","Recall of Hate on Validation: 0.36438923395445133\n","F1-score of Hate on Validation: 0.19166893547508848\n","Epoch [41/50], Step [1000/4846], Loss: 0.8425\n","Epoch [41/50], Step [2000/4846], Loss: 0.3862\n","Epoch [41/50], Step [3000/4846], Loss: 0.5568\n","Epoch [41/50], Step [4000/4846], Loss: 0.6386\n","Test Accuracy on Validation: 60.71185768000519 %\n","F1-score Macro on Validation: 0.504354288760848\n","Precision of Hate on Validation: 0.1278724981467754\n","Recall of Hate on Validation: 0.35714285714285715\n","F1-score of Hate on Validation: 0.18831877729257643\n","Epoch [42/50], Step [1000/4846], Loss: 0.5001\n","Epoch [42/50], Step [2000/4846], Loss: 0.7033\n","Epoch [42/50], Step [3000/4846], Loss: 0.7942\n","Epoch [42/50], Step [4000/4846], Loss: 0.5134\n","Test Accuracy on Validation: 62.95504269724195 %\n","F1-score Macro on Validation: 0.518795740465464\n","Precision of Hate on Validation: 0.14596554850407978\n","Recall of Hate on Validation: 0.3333333333333333\n","F1-score of Hate on Validation: 0.2030264817150063\n","Epoch [43/50], Step [1000/4846], Loss: 0.7203\n","Epoch [43/50], Step [2000/4846], Loss: 0.5905\n","Epoch [43/50], Step [3000/4846], Loss: 0.6494\n","Epoch [43/50], Step [4000/4846], Loss: 0.8195\n","Test Accuracy on Validation: 60.02248459484272 %\n","F1-score Macro on Validation: 0.4998103687191114\n","Precision of Hate on Validation: 0.12311227839789889\n","Recall of Hate on Validation: 0.38819875776397517\n","F1-score of Hate on Validation: 0.1869391824526421\n","Epoch [44/50], Step [1000/4846], Loss: 0.5715\n","Epoch [44/50], Step [2000/4846], Loss: 0.8627\n","Epoch [44/50], Step [3000/4846], Loss: 0.8107\n","Epoch [44/50], Step [4000/4846], Loss: 0.4146\n","Test Accuracy on Validation: 59.26485407056898 %\n","F1-score Macro on Validation: 0.4935232811178636\n","Precision of Hate on Validation: 0.11803381340012524\n","Recall of Hate on Validation: 0.39026915113871635\n","F1-score of Hate on Validation: 0.18125\n","Epoch [45/50], Step [1000/4846], Loss: 0.6406\n","Epoch [45/50], Step [2000/4846], Loss: 0.5072\n","Epoch [45/50], Step [3000/4846], Loss: 0.4697\n","Epoch [45/50], Step [4000/4846], Loss: 0.6062\n","Test Accuracy on Validation: 60.78833530799235 %\n","F1-score Macro on Validation: 0.5032809666458647\n","Precision of Hate on Validation: 0.12518195050946143\n","Recall of Hate on Validation: 0.35610766045548653\n","F1-score of Hate on Validation: 0.1852450188476037\n","Epoch [46/50], Step [1000/4846], Loss: 0.6791\n","Epoch [46/50], Step [2000/4846], Loss: 0.8114\n","Epoch [46/50], Step [3000/4846], Loss: 0.7910\n","Epoch [46/50], Step [4000/4846], Loss: 0.8983\n","Test Accuracy on Validation: 61.59134078362824 %\n","F1-score Macro on Validation: 0.5078391422787605\n","Precision of Hate on Validation: 0.1368006993006993\n","Recall of Hate on Validation: 0.32401656314699795\n","F1-score of Hate on Validation: 0.19237861094038106\n","Epoch [47/50], Step [1000/4846], Loss: 0.6782\n","Epoch [47/50], Step [2000/4846], Loss: 0.7318\n","Epoch [47/50], Step [3000/4846], Loss: 0.6082\n","Epoch [47/50], Step [4000/4846], Loss: 0.5187\n","Test Accuracy on Validation: 62.114218513710455 %\n","F1-score Macro on Validation: 0.5097775169199413\n","Precision of Hate on Validation: 0.1309030654515327\n","Recall of Hate on Validation: 0.32712215320910976\n","F1-score of Hate on Validation: 0.18698224852071002\n","Epoch [48/50], Step [1000/4846], Loss: 0.6916\n","Epoch [48/50], Step [2000/4846], Loss: 0.7401\n","Epoch [48/50], Step [3000/4846], Loss: 0.7728\n","Epoch [48/50], Step [4000/4846], Loss: 0.6405\n","Test Accuracy on Validation: 60.60230622649728 %\n","F1-score Macro on Validation: 0.5009162890324145\n","Precision of Hate on Validation: 0.12132089016511127\n","Recall of Hate on Validation: 0.3498964803312629\n","F1-score of Hate on Validation: 0.18017057569296374\n","Epoch [49/50], Step [1000/4846], Loss: 0.5733\n","Epoch [49/50], Step [2000/4846], Loss: 0.4596\n","Epoch [49/50], Step [3000/4846], Loss: 0.7530\n","Epoch [49/50], Step [4000/4846], Loss: 0.4426\n","Test Accuracy on Validation: 61.986725674401995 %\n","F1-score Macro on Validation: 0.5094493198982198\n","Precision of Hate on Validation: 0.13055666800160193\n","Recall of Hate on Validation: 0.33747412008281574\n","F1-score of Hate on Validation: 0.1882760612185966\n","Epoch [50/50], Step [1000/4846], Loss: 0.5140\n","Epoch [50/50], Step [2000/4846], Loss: 0.6649\n","Epoch [50/50], Step [3000/4846], Loss: 0.6265\n","Epoch [50/50], Step [4000/4846], Loss: 0.6257\n","Test Accuracy on Validation: 62.17563234976074 %\n","F1-score Macro on Validation: 0.5095569867549062\n","Precision of Hate on Validation: 0.13856502242152466\n","Recall of Hate on Validation: 0.3198757763975155\n","F1-score of Hate on Validation: 0.19336670838548184\n","Save outputfile\n"],"name":"stdout"}]}]}